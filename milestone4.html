<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="cache-control" content="no-cache" />
    <meta http-equiv="expires" content="0" />
    <meta http-equiv="pragma" content="no-cache" />
    <link
      href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.1/dist/css/bootstrap.min.css"
      rel="stylesheet"
      integrity="sha384-iYQeCzEYFbKjA/T2uDLTpkwGzCiq6soy8tYaI1GyVh/UjpbCx/TYkiZhlZB6+fzT"
      crossorigin="anonymous"
    />
    <style>
      table {
        font-family: arial, sans-serif;
        border-collapse: collapse;
        width: 100%;
      }

      td,
      th {
        border: 1px solid black;
        text-align: left;
        padding: 8px;
      }

      tr:nth-child(even) {
        background-color: #dddddd;
      }
    </style>
    <title>Team Registration</title>
  </head>
  <body>
    <nav class="navbar navbar-expand-lg bg-dark">
      <div class="container-fluid">
        <a class="navbar-brand text-white" href="index.html"
          >Team Registration</a
        >
        <a class="nav-link text-white" href="index.html">Home</a>
        <a class="nav-link text-white" href="milestone1.html">Milestone 1</a>
        <a class="nav-link text-white" href="milestone2.html">Milestone 2</a>
        <a class="nav-link text-white" href="milestone3.html">Milestone 3</a>
        <a class="nav-link text-white" href="milestone4.html">Milestone 4</a>
      </div>
    </nav>
    <h1 class="text-center">Milestone 4: Prototyping & Testing</h1>
    <div class="container-flex">
      <hr />
      <div class="task-a">
        <h2>A. High-Fidelity Prototype</h2>
        <div>
          <h5>1. Prototype</h5>
          <h6>Assumtions</h6>
          <p>
            Team Registration has created the prototype while following all of
            these assumptions: <br />
          </p>
          <ul>
            <li>The user desires to register for classes.</li>
            <li>The user knows what classes they want to take.</li>
            <li>The user is a computer science major.</li>
            <li>
              The user knows that class registration starts through Athena.
            </li>
            <li>The user has already logged into the system.</li>
          </ul>
          <!--Insert figma embed here -->
        </div>
        <div>
          <h5>2. Extended Description & Demos</h5>
          <ol>
            <li>User Story 1</li>
            <!--Insert demo1 embed here -->
            <li>User Story 2</li>
            <!--Insert demo1 embed here -->
            <li>User Story 3</li>
            <!--Insert demo1 embed here -->
            <li>User Story 4</li>
            <!--Insert demo1 embed here -->
            <li>User Story 5</li>
            <!--Insert demo1 embed here -->
            <li>User Story 6</li>
            <!--Insert demo1 embed here -->
          </ol>
        </div>
      </div>
    </div>
    <hr />
    <div class="task-b">
      <h2>B. Testing Protocol</h2>
      <div>
        <h5>1. Testing Protocol & 2. Testing Procedure</h5>
        <p>
          As a follow-up and implementation of the research conducted by Estevez
          et al. in <em>A model for web-based course registration systems</em>,
          we will examine if a prototype registration system designed under the
          same guidelines as those evaluated by Estevez et al. would be
          preferred by new users to the existing Athena registration system.
          Such an examination involves the following questions:
        </p>
        <ol>
          <li>
            Would a prototype registration system designed utilizing the same
            guidelines evaluated by Estevez et al. be preferable, overall, by
            new users to the existing Athena registration system?
          </li>
          <li>
            How effective and user friendly, for new users specifically, is a
            prototype registration system designed utilizing the same guidelines
            evaluated by Estevez et al. compared to the existing Athena
            registration system on the following quantitative metrics:
          </li>
          <ol>
            <li>Time to register</li>
            <li>Number of errors</li>
            <li>Information clarity</li>
            <li>Intuitiveness</li>
            <li>Visual appeal</li>
            <li>Feelings of control</li>
          </ol>
        </ol>
        <p>
          Note that the data for these metrics will be gathered across an
          experiment (e.g., time to register and number of errors) and a user
          survey (e.g., information clarity, intuitiveness, etc.).
        </p>
        <p>
          As such the methodology to be utilized consists of a mixed methods
          experiment in which we will observe participants and conduct a user
          survey following this observation. The participants of this study
          consist of incoming freshman UGA students
          <em
            >who have not used Athena or our prototype for registration purposes
            prior to this experiment</em
          >. This is to eliminate student bias for or against the Athena
          registration system, and bias in student proficiency with the existing
          Athena system. Students will be approached for the experiment first
          when they apply for their orientation date, and subsequently, in their
          first advising appointment. Students will be able to opt-in or opt-out
          of this experiment at these points. Furthermore, said experiment will
          consist of a control group and an experimental group. The control
          group will utilize the existing Athena registration system, while the
          experimental group will utilize our prototype registration system. In
          order to avoid further bias, these groups are blind―that is, no
          student will know whether they are using the new or old registration
          system during the experiment. Ultimately, by combining an experiment
          with a user survey we can maximize our data collection and potential
          analyses.
        </p>
        <p>
          The choice to conduct a user survey following participant observation
          is primarily because we seek strong methodological control (Evans and
          Mathur, 2005). Take, for instance, some of the primary strengths of
          online surveys as outlined by Evans and Mathur:
        </p>
        <ul>
          <li>Flexibility</li>
          <li>Speed and timeliness</li>
          <li>Convenience</li>
          <li>Ease of data entry and analysis</li>
          <li>Low administration cost</li>
          <li>Ease of follow-up</li>
          <li>Controlled sampling</li>
          <li>Control of answer order</li>
          <li>Required completion of answers</li>
        </ul>
        <p>
          The strengths listed above are particularly pertinent to the data we
          will collect and analyze. Furthermore, the advantages of utilizing an
          online survey outweigh their potential weaknesses in this particular
          case. The most pertinent weaknesses we have identified to this method
          via Evans and Mathur are listed below:
        </p>
        <ul>
          <li>Perception as junk mail</li>
          <li>Skewed attributes of internet population</li>
        </ul>
        <p>
          However, with careful implementation and planning, these weaknesses
          can be mitigated or eliminated entirely (Evans and Mathur, 2005). For
          example, by keeping our survey opt-in and only contacting our
          (potential) participants as needed, we can reduce its perception as
          junk mail.
        </p>
        <p>
          Furthermore, prior to conducting the experiment students will be
          provided with all of the following relevant information
        </p>
        <table>
          <tr>
            <td>What is the purpose of this experiment?</td>
            <td>
              To determine the preferability of a prototype registration system
              designed using Estevez et al.’s guidelines to the existing Athena
              registration system for purposes of keeping or replacing the
              existing system
            </td>
          </tr>
          <tr>
            <td>What is their role in the experiment?</td>
            <td>
              A generalizable sample of the user population to determine
              preferability…
            </td>
          </tr>
          <tr>
            <td>How does this experiment affect them?</td>
            <td>
              <ol>
                <li>Does not affect actual course registration</li>
                <li>
                  Data is used to determine what future registration system UGA
                  will utilize
                </li>
              </ol>
            </td>
          </tr>
        </table>
        <p>
          Specifically, students will be told that we are testing out a new
          (prototype) registration system using them as a sample population and
          that their participation will not actually affect their course
          registration selection. In other words, the course selections and
          changes they make when participating in this experiment do not count
          towards their actual registration. Furthermore, after participating in
          the experiments, users will then be allowed to genuinely register for
          their courses on the actual system. After providing students with this
          information, we will ask them if, first, they fully understand the
          purpose and terms of this study, and then, if they would wish to
          participate/opt-in. Following all these steps ensures that there is
          adequate informed consent across the information, comprehension, and
          voluntariness requirements of the Belmont Report for informed consent:
          students are presented with all the relevant information, understand
          what we have told them, and are voluntarily opting in (Office for
          Human Research Protections, 2022).
        </p>
        <p>
          We will collect the data on time to register and number of errors
          through participant observation during the experiment. Following this
          experiment, students will complete a survey in which they will rate
          the following factors on a scale from 1-10, (1 being least and 10
          being most): information clarity, intuitiveness, visual appeal, and
          feelings of control. These metrics are defined as follows, where the
          prototype is the treatment and the existing Athena system is the
          control in this experiment:
        </p>
        <ol>
          <li>
            <strong>Time to register</strong> is how long it takes for students
            to register for all their classes using either the prototype or the
            existing Athena system.
          </li>
          <li>
            <strong>Number of errors</strong> is the number of mistakes or
            errors users make while using the prototype and the existing Athena
            system.
          </li>
          <li>
            <strong>Information clarity</strong> is how clear the information is
            presented on the screen according to the participant.
          </li>
          <li>
            <strong>Intuitiveness</strong> is how easy it was to learn and use
            the appropriate registration system according to the participant.
          </li>
          <li>
            <strong>Visual appeal</strong> is how the participant rates the
            design and appearance of the appropriate registration system.
          </li>
          <li>
            <strong>Feelings of control</strong> is how comfortable and in
            control the participant felt while using the appropriate
            registration system during the experiment.
          </li>
        </ol>
        <p>
          As all of the above metrics are numeric in nature, data analysis will
          be performed by calculating the averages for each variable across the
          treatment and control groups. In other words, we will calculate the
          average time to register, number of errors, information clarity,
          intuitiveness, visual appeal, and feelings of control for students who
          used our prototype versus for students who used the existing Athena
          system. Thus, we will compare how these averages vary across the
          treatment and control groups to determine our answers to research
          questions <strong>(1)</strong> and <strong>(2)</strong>. Ideally, this
          comparison should reveal how well our prototype performed against the
          existing Athena registration system overall <strong>(1)</strong> and
          specifically across the different dimensions for which we collected
          data <strong>(2)</strong>.
        </p>
        <p>
          Lastly, to ensure safety in conducting our experiment and survey in
          light of the pandemic, we will allow all students to use their
          personal devices as opposed to computers in public computer labs. In
          addition, students will be provided with device and hand sanitation
          gels and wipes. While this will work to mitigate disease spread
          through touch, it could potentially impact the time to register and
          number of errors metrics. Furthermore, students will be encouraged to
          wear a mask and socially distance themselves from other participants
          if they have symptoms of illness and as necessary.
        </p>
      </div>
    </div>
    <hr />
    <div class="text-center task-c">
      <h2>C. Summary Video</h2>
      <!--Insert YouTube video-->
    </div>
    <hr />
    <script
      src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.1/dist/js/bootstrap.bundle.min.js"
      integrity="sha384-u1OknCvxWvY5kfmNBILK2hRnQC3Pr17a+RTT6rIHI7NnikvbZlHgTPOOmMi466C8"
      crossorigin="anonymous"
    ></script>
  </body>
</html>
